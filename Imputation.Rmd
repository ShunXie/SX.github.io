---
title: "Data"

output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background Information of the datasets

<br>
<br>


### Life Expectancy Dataset

We choose WHO Life Expectancy Dataset as our main dataset in our study. The data can be accessed [here](https://www.kaggle.com/datasets/mmattson/who-national-life-expectancy?resource=download). The code is read as following:

```{r,message=FALSE, warning=FALSE}
suppressMessages(library(tidyverse))
suppressMessages(library(dbplyr))
options(tibble.print_min = 5)

#Get life expectancy data
LifeExpectancy = read_csv("data/who_life_exp.csv",col_types = cols(.default = col_guess())) %>% 
  janitor::clean_names()


```
Life expectancy datasets contains a total of ```r length(unique(LifeExpectancy$country))``` countries with year ranging from ```r min(unique(LifeExpectancy$year))``` to ```r max(unique(LifeExpectancy$year))```. There are a total of ```r length(LifeExpectancy)``` variables. Out of which, we consider the variables and description is listed below:

*```r colnames(LifeExpectancy)[1]```: country name

*```r colnames(LifeExpectancy)[2]```: Three letter of the country id

*```r colnames(LifeExpectancy)[3]```: The region of the country

*```r colnames(LifeExpectancy)[4]```: year of all values stored

*```r colnames(LifeExpectancy)[5]```: Life expectancy at birth measured in year. It is continuous variable.

*```r colnames(LifeExpectancy)[6]```: Life expectancy at age 60 measured in year. It is continuous variable.

*```r colnames(LifeExpectancy)[7]```: Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)

*```r colnames(LifeExpectancy)[8]```: Death rate up to age 1

*```r colnames(LifeExpectancy)[9]```: Death rate between ages 1 and 4

*```r colnames(LifeExpectancy)[10]```: Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)

*```r colnames(LifeExpectancy)[11]```: Mean BMI (kg/$m^2$) (18+) (age-standardized estimate)

*```r colnames(LifeExpectancy)[12]```: Prevalence of thinness among children and adolescents. This is measured in a crude estimate percentage for children with BMI < (median - 2 s.d.)

*```r colnames(LifeExpectancy)[13]```: Prevalence of obesity  among children and adolescents. This is measured in a crude estimate percentage for children with BMI < (median - 2 s.d.)

*```r colnames(LifeExpectancy)[14]```: Hepatitis B (HepB) immunization coverage among 1-year-olds (%)

*```r colnames(LifeExpectancy)[15]```: Measles-containing-vaccine first-dose (MCV1) immunization coverage among 1-year-olds (%)

*```r colnames(LifeExpectancy)[16]```: Polio (Pol3) immunization coverage among 1-year-olds (%)

*```r colnames(LifeExpectancy)[17]```: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)

*```r colnames(LifeExpectancy)[18]```: Population using at least basic drinking-water services

*```r colnames(LifeExpectancy)[19]```: Number of medical doctors (per 10,000)

*```r colnames(LifeExpectancy)[20]```: Total density of hospitals per 100 000 population

*```r colnames(LifeExpectancy)[21]```: Gross national income per capita in dollars. This is measured from GHO server

*```r colnames(LifeExpectancy)[22]```: Domestic general government health expenditure (GGHE-D) as percentage of gross domestic product (GDP). This is measured from GHO server

*```r colnames(LifeExpectancy)[23]```: Current health expenditure (CHE) as percentage of gross domestic product (GDP) (%) 

*```r colnames(LifeExpectancy)[24]```: Population (thousands) 

*```r colnames(LifeExpectancy)[25]```: Mortality rate, infant (per 1,000 live births). This is measured from GHO server

*```r colnames(LifeExpectancy)[26]```: (Our response variable) Life expectancy at birth, total (years). This is measured from GHO server. It is contains less missing value than life expectancy. 

*```r colnames(LifeExpectancy)[27]```: Prevalence of HIV, total (% of population ages 15-49). This is measured from GHO server

*```r colnames(LifeExpectancy)[28]```: GNI per capita, PPP (current international $). This is measured from UNESCO  server

*```r colnames(LifeExpectancy)[29]```: Government expenditure on education as a percentage of GDP (%). This is measured from UNESCO  server

*```r colnames(LifeExpectancy)[30]```: Adult literacy rate, population 15+ years, both sexes (%). This is measured from UNESCO  server

*```r colnames(LifeExpectancy)[31]```: Mean years of schooling (ISCED 1 or higher), population 25+ years, both sexes. This is measured from UNESCO  server




<br>
<br>

### Country Code Dataset


Country code dataset contains the status of countries, such as the information of the independence status and its capital city. The data is extracted from [here](https://github.com/datasets/country-codes/blob/master/data/country-codes.csv). We include the variable specifies whether the country is a developed or developing country. The data is read in the following code and is merged by the code.  


```{r,message=FALSE, warning=FALSE}
country_code = 
  read_csv("data/country-codes.csv", show_col_types = FALSE) %>% 
  select(`ISO3166-1-Alpha-3`, `Developed / Developing Countries`)



merged_data_PM = merge(LifeExpectancy, country_code, by.x = "country_code", by.y = "ISO3166-1-Alpha-3" )
```


<br>
<br>


### PM2.5 dataset
PM2.5 dataset is a dataset that specifies the percentage of total population exposed to levels exceeding WHO guideline value. Such value exists over year 1960 to 2021 but most of the value before 2010 and after 2017 are missing. The dataset can be accessed [here](https://data.worldbank.org/indicator/EN.ATM.PM25.MC.M3). The following code read and clean the dataset.

merge the data with dataset contain pm 2.5 information:
```{r,message=FALSE, warning=FALSE}

#read pm2.5 data
PM_dataset = 
  read_csv("data/pm2.5.csv", show_col_types = FALSE, skip = 4) 

PM_dataset_clean = 
  PM_dataset %>% 
  janitor::clean_names() %>% 
  select(-(x1960:x1999),-(x2017:x2021)) %>% 
  pivot_longer(
    x2000:x2016,
    names_to = "year",
    names_prefix = "x",
    values_to = "PM_value"
  ) %>% 
  select(country_code, year, PM_value) %>% 
  mutate(year = as.numeric(year))
```

The following code is used to merge with all dataset.

```{r,message=FALSE, warning=FALSE}
#merged data with developed/ developing countries
merged_data_d = 
  merged_data_PM %>% 
  left_join(PM_dataset_clean, by = c("country_code","year"))
```


<br>
<br>

### Income level data

Income level data is a dataset specifies the income status accessed [here](https://databank.worldbank.org/source/world-development-indicators). It is a factor variable with four levels, namely high income, low income, lower middle income and upper middle income. The dataset is cleaned and merged in the following code. 

```{r,message=FALSE, warning=FALSE}
#read income level data
Income_dataset = read_csv("data/income_level.csv", show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  select(country_code,income_group)

#merged data with income level
merged_data_i = merged_data_d %>% 
  left_join( Income_dataset, by = c("country_code")) %>% 
  select(country_code:une_school,PM_value,income_group,`Developed / Developing Countries`)
```

<br>
<br>


### Health expenditure

Health expenditure dataset measures the health expenditure from government with respect to different countries. The dataset is retrieved from [here](https://ourworldindata.org/grapher/public-health-expenditure-share-gdp-owid?country=SWE~FRA~DEU~JPN~GBR~BEL~ESP~AUS~NZL~CAN~USA). The dataset is measured in percentage of GDP or dollar value per capita. We choose percentage of GDP as our unit because the dataset measured in percentage of GDP has more complete values. Here is the coding for read, clean and merge the Health expenditure dataset to original dataset. 

```{r,message=FALSE, warning=FALSE}
health_exp = read_csv("data/government_compulsory_health expenditure_from_1970_2020.csv") %>% 
  janitor::clean_names() %>% 
  filter(measure=="PC_GDP") %>%
  filter(subject=="TOT") %>% 
  mutate("country_code"=location,
         "year" = time) %>% 
  select(country_code,year, value)

merged_data_h = 
  merged_data_i %>% 
  left_join(health_exp, by = c("country_code","year")) %>% 
  mutate("health_exp" = value) %>% 
  select(country_code:une_school,PM_value,income_group,health_exp,`Developed / Developing Countries`)
```

<br>
<br>


### Parliament Information

Parliament information data is a dataset that measured the percentage of women in national parliament around 2015~2018 for different countries. Since different countries have different election dates, and there is rare data before 2015, we choose the dataset that is around 2015~2018. Then, we adjust the date to year 2015, and add the percentage of women in lower house of national parliament to the last column of the original dataset. The data origins from [here](https://data.ipu.org/women-ranking?month=1&year=2019) and the following code cleans and merge the data:

```{r,message=FALSE, warning=FALSE}
women_in_parliament <-
  read_csv("data/around_2019_women_percent_in_national_parliaments.csv", skip = 5) %>% 
  janitor::clean_names() %>% 
  select(x2, elections_3, percent_w_6) %>% 
  mutate("country" = x2,
         "percent_w_in_lower_house" = percent_w_6,
         "year" = as.double(2015)) %>% 
  select(country, year, percent_w_in_lower_house)

merged_data = 
  merged_data_h %>% 
  left_join(women_in_parliament, by = c("country","year")) %>% 
  select(country_code:une_school,PM_value,health_exp,income_group,`Developed / Developing Countries`, percent_w_in_lower_house)

```


Store the data
```{r}
write.csv(merged_data , file = "data/Merged_expectation.csv")
```

<br>
<br>

# Impute

For the simplicity and accuracy purpose, imputation using weighted k nearest neighbour algorithm (w-kNN) is considered in my study. It is built on simple k nearest neighbour(kNN) but unlike kNN, it considers the weight of each dimension so that it circumvents the problem of neglecting the correlation between missing variables and other variables according to [Ling et. al.](https://ieeexplore.ieee.org/abstract/document/5199781). Additionally, such a non-parametric method does not make any assumption on the distribution of the input vector hence it is suitable for correlation analysis by [mukid's paper](https://iopscience.iop.org/article/10.1088/1742-6596/1025/1/012114/meta). In my method, we choose Euclidean distance as my measurement for the similarity between authorities as it performs better than the other metrics, namely [Manhattan distance](https://ieeexplore.ieee.org/abstract/document/6873626). Thus, any missing value $x_{i,j}$ at time t can be imputed using an inverse of Euclidean distance as a weighting factor, where the subscript i corresponds to the $i_{th}$ country and subscript j represents the $j_{th}$ sub-indicator (or the $j_{th}$ variable in the dataset).  \\

To obtain the imputation for missing value $x_{i,j}$, euclidean distances between all underlying pairs of country $(a_i,a_k)$ at year t without missing value need to be calculated. The pair with the largest euclidean distance $d_t(a_i,a_k) $, however, will not be considered, and instead it is treated as the denominator for standardization of other available euclidean distance values. For a pair of country $(a_i,a_k)$ at year t, the euclidean distance $d_t(a_i,a_k) $ can be obtained by the following formula:
\[
\begin{equation}
\mathbf{d}_t(a_i,a_k)=||a_i,a_k||=\sqrt{\sum_{j=1}^J w(a_{ij}-a_{kj})^2}
\end{equation}
\]
where J is the total number of variables or non missing data and w is the weighting function by [Ling et. al.](https://ieeexplore.ieee.org/abstract/document/5199781). As my available data may have different length due to different number of missing values, I choose $w=\frac{1}{J}$ as my weight in the Euclidean distance. Then, I can normalize the Euclidean distance by dividing the largest euclidean distance in the available data set for country i. Without loss of generality, let $\mathbf{d}_t(a_i,a_l)$ be the maximum euclidean distance for country i. Then for  $k\neq l$:
\[
\begin{equation}
\mathbf{D}_t(a_i,a_k)=\frac{\mathbf{d}_t(a_i,a_k)}{\mathbf{d}_t(a_i,a_{l})}
\end{equation}
\]

To balance the size of the imputed value for missing value $x_{i,j}$, I consider the weight as the inverse of Euclidean distance. Such an approach is validated in [Laumann et. al's work](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3777229) where they believe the imputed value will be similar to countries with sub-indicator that has small Euclidean distance. With all other things being equal, countries are replaced by authorities and sub-indicators are variables in my data. Hence, having computed euclidean distances between all possible pairs and years, the missing value is measured as:

\begin{equation}
x^t_{i,j}=\frac{1}{K}\sum_k \frac{1}{|\mathbf{D}_t(a_i,a_k)|}x^t_{k,j}
\end{equation}
where K is the total number of countries that have values at year t for variable j.

This is nicely packed in filling package in R. In our case, we choose k to be 4. This is according to the income level of countries. More detail is justified in clustering part in our analysis.

```{r,message=FALSE, warning=FALSE}
raw_mat = 
  merged_data %>% 
  select(-country, -country_code, -region,-income_group, -`Developed / Developing Countries`,percent_w_in_lower_house) %>% 
  as.matrix()

imputed_mat = filling::fill.KNNimpute(raw_mat, k = 2)

```

```{r,essage=FALSE, warning=FALSE}
#colnames_exp = colnames(LifeExpectancy)
Imputed_expectancy = merged_data
for (i in 1:(length(merged_data)-6)) {
  Imputed_expectancy[i+3][[1]] = imputed_mat[[1]][,i]
}
head(Imputed_expectancy %>% select(-percent_w_in_lower_house))

write.csv(Imputed_expectancy , file = "data/Imputed_expectation.csv")
```







